{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to download the title, description and inclusion/exclsion criteria for oncology trials  using clinicaltrials.gov api.\n",
    "\n",
    "Author - Akshay Chougule<br>\n",
    "Created on - 30th May 2020<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'being\\', \\'your\\', \\'t\\', \\'hadn\\', \\'yours\\', \\'to\\', \\'off\\', \"mustn\\'t\", \\'here\\', \\'won\\', \\'our\\', \"you\\'d\", \\'weren\\', \\'he\\', \\'her\\', \\'but\\', \\'ain\\', \\'and\\', \\'m\\', \\'a\\', \\'at\\', \"weren\\'t\", \\'the\\', \\'it\\', \\'each\\', \\'who\\', \\'more\\', \\'than\\', \\'my\\', \\'o\\', \\'wasn\\', \\'we\\', \\'until\\', \\'should\\', \"it\\'s\", \\'this\\', \\'hasn\\', \\'didn\\', \\'once\\', \\'or\\', \\'during\\', \"shan\\'t\", \\'nor\\', \\'if\\', \\'himself\\', \"she\\'s\", \\'me\\', \\'yourself\\', \\'doesn\\', \\'up\\', \\'all\\', \\'having\\', \\'mustn\\', \\'their\\', \\'above\\', \\'can\\', \"wasn\\'t\", \\'between\\', \\'had\\', \\'which\\', \\'of\\', \\'am\\', \\'shouldn\\', \\'about\\', \"won\\'t\", \\'those\\', \\'needn\\', \\'his\\', \\'re\\', \\'too\\', \\'such\\', \\'out\\', \\'y\\', \\'on\\', \\'mightn\\', \\'some\\', \\'while\\', \\'ma\\', \\'below\\', \\'wouldn\\', \\'hers\\', \\'haven\\', \\'just\\', \\'herself\\', \\'after\\', \\'ourselves\\', \\'is\\', \\'from\\', \\'then\\', \"mightn\\'t\", \\'she\\', \\'how\\', \\'been\\', \\'shan\\', \\'as\\', \\'against\\', \"that\\'ll\", \\'be\\', \\'couldn\\', \\'most\\', \\'in\\', \\'over\\', \\'an\\', \\'not\\', \"wouldn\\'t\", \\'other\\', \"doesn\\'t\", \\'now\\', \\'further\\', \\'same\\', \\'s\\', \\'do\\', \\'myself\\', \\'i\\', \\'aren\\', \"didn\\'t\", \\'by\\', \\'theirs\\', \"don\\'t\", \\'into\\', \\'its\\', \\'that\\', \\'down\\', \"you\\'ll\", \\'only\\', \\'themselves\\', \\'through\\', \\'don\\', \\'ll\\', \\'ve\\', \\'for\\', \\'with\\', \\'own\\', \\'whom\\', \\'both\\', \\'have\\', \"you\\'re\", \"hadn\\'t\", \\'are\\', \\'did\\', \\'d\\', \\'him\\', \\'what\\', \"needn\\'t\", \\'were\\', \\'why\\', \\'when\\', \\'few\\', \\'itself\\', \\'again\\', \"you\\'ve\", \\'yourselves\\', \\'ours\\', \\'has\\', \\'no\\', \"hasn\\'t\", \"isn\\'t\", \\'before\\', \"haven\\'t\", \\'will\\', \"aren\\'t\", \\'these\\', \\'there\\', \\'them\\', \\'so\\', \\'doing\\', \\'where\\', \\'because\\', \\'very\\', \"couldn\\'t\", \"shouldn\\'t\", \\'was\\', \\'you\\', \\'does\\', \\'they\\', \\'under\\', \"should\\'ve\", \\'any\\', \\'isn\\'}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Get nltk stopword list into a set.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "str(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'is\\', \\'interventions\\', \\'study\\', \\'from\\', \\'for\\', \\'with\\', \\'to\\', \\'must\\', \\'prior\\', \\'have\\', \\'six\\', \\'as\\', \\'are\\', \\'(\\', \\'five\\', \\'of\\', \\'but\\', \\'use\\', \\')\\', \\'be\\', \\'and\\', \\'a\\', \\'two\\', \\'in\\', \\'at\\', \\'an\\', \\'one\\', \\'not\\', \\'the\\', \\'see\\', \\'start\\', \\'four\\', \\'since\\', \\'other\\', \\'patients\\', \\'has\\', \\'no\\', \\'\"\\', \\'three\\', \\'than\\', \\'before\\', \\'except\\', \\'below\\', \\'greater\\', \\',\\', \\'none\\', \\'by\\', \\'or\\', \\'allowed\\', \\'they\\', \\'any\\'}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words2 = set('for a ( of the ) study interventions and to in is at an must be with are but not no none has have other from as prior or except none see below study , use \" one two three four five six patients before start greater than any allowed by for they since'.split())\n",
    "str(stop_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'being\\', \\'your\\', \\'study\\', \\'t\\', \\'hadn\\', \\'yours\\', \\'to\\', \\'off\\', \"mustn\\'t\", \\'here\\', \\'won\\', \\'our\\', \"you\\'d\", \\'weren\\', \\'he\\', \\'her\\', \\'but\\', \\'ain\\', \\'and\\', \\'m\\', \\'a\\', \\'at\\', \"weren\\'t\", \\'the\\', \\'it\\', \\'since\\', \\'each\\', \\'who\\', \\'more\\', \\'three\\', \\'than\\', \\'my\\', \\'o\\', \\'wasn\\', \\'we\\', \\'until\\', \\'should\\', \"it\\'s\", \\'this\\', \\'hasn\\', \\'didn\\', \\'once\\', \\'or\\', \\'during\\', \"shan\\'t\", \\'nor\\', \\'if\\', \\'himself\\', \"she\\'s\", \\'me\\', \\'yourself\\', \\'doesn\\', \\'up\\', \\'all\\', \\'having\\', \\'mustn\\', \\'their\\', \\'prior\\', \\'above\\', \\'can\\', \"wasn\\'t\", \\'between\\', \\'had\\', \\'five\\', \\'which\\', \\'of\\', \\'am\\', \\'shouldn\\', \\'about\\', \"won\\'t\", \\'those\\', \\'needn\\', \\'two\\', \\'his\\', \\'re\\', \\'four\\', \\'too\\', \\'patients\\', \\'such\\', \\'out\\', \\'y\\', \\'on\\', \\'mightn\\', \\'some\\', \\'while\\', \\'ma\\', \\'below\\', \\'greater\\', \\'wouldn\\', \\'hers\\', \\'haven\\', \\'just\\', \\'herself\\', \\'allowed\\', \\'after\\', \\'ourselves\\', \\'is\\', \\'interventions\\', \\'from\\', \\'then\\', \"mightn\\'t\", \\'she\\', \\'how\\', \\'been\\', \\'shan\\', \\'as\\', \\'use\\', \\'against\\', \"that\\'ll\", \\'be\\', \\'couldn\\', \\'most\\', \\'in\\', \\'over\\', \\'an\\', \\'one\\', \\'not\\', \"wouldn\\'t\", \\'other\\', \"doesn\\'t\", \\'now\\', \\'further\\', \\'same\\', \\'s\\', \\'do\\', \\'except\\', \\'myself\\', \\',\\', \\'i\\', \\'aren\\', \"didn\\'t\", \\'by\\', \\'theirs\\', \"don\\'t\", \\'into\\', \\'its\\', \\'that\\', \\'down\\', \"you\\'ll\", \\'only\\', \\'themselves\\', \\'through\\', \\'don\\', \\'ll\\', \\'ve\\', \\'for\\', \\'with\\', \\'must\\', \\'own\\', \\'whom\\', \\'both\\', \\'have\\', \"you\\'re\", \"hadn\\'t\", \\'six\\', \\'are\\', \\'did\\', \\'d\\', \\'him\\', \\'(\\', \\'what\\', \\')\\', \"needn\\'t\", \\'were\\', \\'why\\', \\'when\\', \\'few\\', \\'itself\\', \\'again\\', \"you\\'ve\", \\'yourselves\\', \\'start\\', \\'see\\', \\'ours\\', \\'has\\', \\'no\\', \"hasn\\'t\", \\'\"\\', \"isn\\'t\", \\'before\\', \"haven\\'t\", \\'will\\', \"aren\\'t\", \\'these\\', \\'there\\', \\'them\\', \\'so\\', \\'doing\\', \\'where\\', \\'because\\', \\'none\\', \\'very\\', \"couldn\\'t\", \"shouldn\\'t\", \\'was\\', \\'you\\', \\'does\\', \\'they\\', \\'under\\', \"should\\'ve\", \\'any\\', \\'isn\\'}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_stop_words = stop_words.union(stop_words2)\n",
    "str(master_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8943395 stop words found and removed\n",
      "Saved as 'stopwords-removed.txt' \n"
     ]
    }
   ],
   "source": [
    "# Open and read in a text file.\n",
    "txt_file = open(\"/home/ubuntu/datasets/cancer-clinical-trials/labeledEligibilitySample1000000.txt\")\n",
    "txt_line = txt_file.read()\n",
    "txt_words = txt_line.split()\n",
    " \n",
    "# stopwords found counter.\n",
    "sw_found = 0\n",
    " \n",
    "# If each word checked is not in stopwords list,\n",
    "# then append word to a new text file.\n",
    "for check_word in txt_words:\n",
    "    if not check_word.lower() in master_stop_words:\n",
    "        # Not found on stopword list, so remove noise and then append.\n",
    "        check_word = check_word.replace('(','').replace(')','').replace('[','').replace(']','').replace('.','').replace('-','').replace(':','').replace('.','')\n",
    "        appendFile = open('/home/ubuntu/datasets/cancer-clinical-trials/1M_cancer_trial_eligibility_preprocessed.txt','a')\n",
    "        appendFile.write(\" \"+check_word)\n",
    "        appendFile.close()\n",
    "    else:\n",
    "        # It's on the stopword list\n",
    "        sw_found +=1\n",
    "        #print(check_word)\n",
    "\n",
    "print(sw_found,\"stop words found and removed\")\n",
    "print(\"Saved as 'stopwords-removed.txt' \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training on Cancer trial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 2.3 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext) (2.5.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/ubuntu/.local/lib/python3.6/site-packages (from fasttext) (45.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.6/site-packages (from fasttext) (1.18.1)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3173570 sha256=f5897a7aa95461d44db97e2b5e627864b3ccd78ba756974385849c46cb94fe00\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/c3/5c/d0/4a725c6ee7df3267d818d3bc9d89bb173b94832f2b9eca6368\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised('/home/ubuntu/datasets/cancer-clinical-trials/1M_cancer_trial_eligibility_preprocessed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02196198,  0.12391646,  0.13404952,  0.18138213,  0.04413488,\n",
       "        0.18806663,  0.25214043,  0.10602474,  0.28508407, -0.07287144,\n",
       "        0.8035991 , -0.29302526,  0.62895876, -0.12890631,  0.04837237,\n",
       "        0.06768012,  0.04129648, -0.5938437 ,  0.38910812,  0.50719196,\n",
       "        0.90053403, -0.4737405 ,  0.142965  ,  0.773092  ,  0.56227523,\n",
       "        0.06776884, -0.5678581 ,  0.5214773 ,  0.08030684, -0.6906355 ,\n",
       "        0.21252692,  0.31908318, -0.03269489,  0.04802901, -0.13038303,\n",
       "       -1.0319707 , -0.25387838,  1.0011411 , -0.20405711,  0.16535135,\n",
       "        0.2999551 , -0.35183156, -0.17931534, -0.19283974, -0.07703391,\n",
       "       -0.01197859, -0.5908381 , -0.16636941, -0.27477872, -0.3364141 ,\n",
       "       -0.00383568,  0.09149738,  0.17858836, -0.18495567,  0.3213171 ,\n",
       "       -0.41683763, -0.66784984, -0.22615245,  0.31174737, -0.16621633,\n",
       "        0.15924199, -0.0219992 , -0.12436614, -0.24230647, -0.10695533,\n",
       "       -0.3250166 , -0.335125  , -0.6373275 , -0.053503  ,  0.2005491 ,\n",
       "        0.02908888, -0.31561223,  0.03370006,  0.10273352, -0.10643701,\n",
       "       -0.23275091, -0.35718268,  0.3566879 , -0.7581506 ,  0.13350382,\n",
       "        0.4249205 , -0.2834457 , -0.43462268, -0.05533136,  0.1659056 ,\n",
       "        0.09485071, -0.39293614, -0.31018984, -0.01792555,  0.7435647 ,\n",
       "        0.15331677,  0.23612824,  0.28983122, -0.14621688,  0.31253552,\n",
       "       -0.15232809,  0.23780641,  0.19846179,  0.2534034 , -0.26611   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_vector(\"estrogen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9248054623603821, 'progesterone'),\n",
       " (0.9014894366264343, 'estroge'),\n",
       " (0.873781144618988, 'progesterones'),\n",
       " (0.8621060848236084, 'receptor'),\n",
       " (0.8285125494003296, 'estrogens'),\n",
       " (0.8080430030822754, 'oestrogens'),\n",
       " (0.8055126667022705, 'oestrogen'),\n",
       " (0.8045371174812317, 'estrogenic'),\n",
       " (0.7995848059654236, 'recepto'),\n",
       " (0.7740491628646851, 'breast')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('estrogen') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8714774250984192, 'Nivolumab'),\n",
       " (0.794731080532074, 'Tremelimumab'),\n",
       " (0.7138570547103882, 'PDR001'),\n",
       " (0.7095555663108826, 'Docetaxel'),\n",
       " (0.705943763256073, 'Monoclonal'),\n",
       " (0.6988462805747986, 'Lenvatinib'),\n",
       " (0.6959121227264404, 'Antibodies,'),\n",
       " (0.6905092000961304, 'Cisplatin'),\n",
       " (0.6884687542915344, 'MGCD265'),\n",
       " (0.6822120547294617, 'Axitinib')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('Pembrolizumab') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6703999638557434, 'cohort'),\n",
       " (0.6480443477630615, 'BIW8962'),\n",
       " (0.6437572240829468, '2%'),\n",
       " (0.6420202255249023, 'Pemetrexed'),\n",
       " (0.6418660879135132, 'Rociletinib'),\n",
       " (0.638372004032135, 'nsclc'),\n",
       " (0.6365253329277039, '4%'),\n",
       " (0.6157108545303345, 'PLX8394'),\n",
       " (0.6140182018280029, 'expansion'),\n",
       " (0.6118809580802917, 'Ponatinib')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors('NSCLC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.570726752281189, 'anticancer'),\n",
       " (0.5494672060012817, 'antitumor'),\n",
       " (0.542633593082428, 'nitroureas'),\n",
       " (0.5291298031806946, 'immunostimulatory'),\n",
       " (0.527664303779602, 'immunotherapies'),\n",
       " (0.5155563354492188, 'NMS1286937'),\n",
       " (0.5106099247932434, 'khk'),\n",
       " (0.5059861540794373, 'cardiopathy'),\n",
       " (0.5022950172424316, 'cardiogenic'),\n",
       " (0.5016393661499023, 'endocrinotherapy')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies(\"immunotherapy\",\"oncology\",\"cardiovascular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getNN(): incompatible function arguments. The following argument types are supported:\n    1. (self: fasttext_pybind.fasttext, arg0: str, arg1: int, arg2: str) -> List[Tuple[float, str]]\n\nInvoked with: <fasttext_pybind.fasttext object at 0x7fca847f1ce0>, ['estrogen', 'progesterone'], 10, 'strict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-df581626fa41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estrogen'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'progesterone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mget_nearest_neighbors\u001b[0;34m(self, word, k, on_unicode_error)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unicode_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unicode_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     def get_analogies(self, wordA, wordB, wordC, k=10,\n",
      "\u001b[0;31mTypeError\u001b[0m: getNN(): incompatible function arguments. The following argument types are supported:\n    1. (self: fasttext_pybind.fasttext, arg0: str, arg1: int, arg2: str) -> List[Tuple[float, str]]\n\nInvoked with: <fasttext_pybind.fasttext object at 0x7fca847f1ce0>, ['estrogen', 'progesterone'], 10, 'strict'"
     ]
    }
   ],
   "source": [
    "model.get_nearest_neighbors(['estrogen','progesterone']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
